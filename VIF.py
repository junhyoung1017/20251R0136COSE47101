import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.lines import Line2D
from sklearn.datasets import make_blobs
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.manifold import TSNE
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.decomposition import TruncatedSVD
from scipy.spatial.distance import cdist,pdist,squareform
from IPython.display import display

data=pd.read_csv('C:/Users/jun01/OneDrive/ë°”íƒ• í™”ë©´/ê³ ë ¤ëŒ€/ë°ê³¼/TermProject/github/data/github_profiles_total_v2_re.csv')
X=data
df=data.drop(columns=["user_ID","username","repo_count"])

svd = TruncatedSVD(n_components=min(df.shape), random_state=42)
svd.fit(df)

explained = np.cumsum(svd.explained_variance_ratio_)

# ì‹œê°í™”
plt.plot(explained, marker='o')
plt.xlabel("Number of SVD Components")
plt.ylabel("Cumulative Explained Variance")
plt.title("TruncatedSVD - Cumulative Variance Explained")
plt.grid(True)
plt.show()

# ì¶œë ¥ ì˜ˆì‹œ
for i, v in enumerate(explained[:12]):
    print(f"Component {i+1}: {v:.4f}")

# ì»´í¬ë„ŒíŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
loadings = pd.DataFrame(
    svd.components_.T,  # shape: (n_features, n_components)
    index=df.columns,   # ì›ë˜ í”¼ì²˜ëª…
    columns=[f"Component_{i+1}" for i in range(svd.n_components)]
)

# ì ˆëŒ“ê°’ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ê¸°ì—¬ í”¼ì²˜ ì¶œë ¥
for i in range(12):  # ì˜ˆ: ì• 5ê°œ ì„±ë¶„ë§Œ ë¶„ì„
    print(f"\nğŸ“Œ Component {i+1}ì˜ ì£¼ìš” ê¸°ì—¬ í”¼ì²˜:")
    display(loadings.iloc[:, i].abs().sort_values(ascending=False).head(5))