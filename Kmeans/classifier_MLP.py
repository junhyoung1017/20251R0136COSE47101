import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, hamming_loss, jaccard_score
from tensorflow.keras import models, layers, callbacks
from tensorflow.keras.optimizers import Adam
import warnings
warnings.filterwarnings('ignore')

# ë°ì´í„° ë¡œë“œ
def load_processed_data():
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ"""
    print("ğŸ“ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì¤‘...")

    # SMOTE ì ìš©ëœ ë¶„í•  ë°ì´í„° ì‚¬ìš©
    X_train = np.load('X_train_balanced.npy')
    X_test = np.load('X_test_balanced.npy')
    y_train = np.load('y_train_balanced.npy')
    y_test = np.load('y_test_balanced.npy')

    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ë¡œë“œ
    with open('class_weights.pkl', 'rb') as f:
        class_weights = pickle.load(f)



   # íƒ€ê¹ƒ ìŠ¤íƒ ê³ ì • (7ê°œ)
    target_stacks = ['Server', 'System', 'Visualization', 'Frontend', 'Android', 'ML-Data', 'iOS']

    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
    print(f"   í›ˆë ¨ ë°ì´í„°: {X_train.shape}")
    print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")
    print(f"   y_train shape: {y_train.shape}")
    print(f"   y_test shape: {y_test.shape}")

    # âš ï¸ y ë°ì´í„°ê°€ 25ì°¨ì›ì´ë¼ë©´ 7ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ í•„ìš”
    if y_train.shape[1] != 7:
        print(f"âš ï¸ y ë°ì´í„° ì°¨ì› ë¶ˆì¼ì¹˜: {y_train.shape[1]} != 7")
        print("   â†’ ë©”íƒ€ë°ì´í„°ì—ì„œ ì˜¬ë°”ë¥¸ íƒ€ê¹ƒ ìŠ¤íƒ ìˆœì„œ í™•ì¸ í•„ìš”")

        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì‹¤ì œ ìŠ¤íƒ ìˆœì„œ í™•ì¸
        with open('metadata_enhanced.pkl', 'rb') as f:
            metadata = pickle.load(f)

        original_target_stacks = metadata['target_stacks']
        print(f"   ì›ë³¸ íƒ€ê¹ƒ ìŠ¤íƒ: {original_target_stacks}")

        # 7ê°œ ê¸°ë³¸ ìŠ¤íƒì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
        target_indices = []
        for stack in target_stacks:
            if stack in original_target_stacks:
                target_indices.append(original_target_stacks.index(stack))
            else:
                print(f"âŒ {stack}ì´ ì›ë³¸ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤!")

        print(f"   ì‚¬ìš©í•  ì¸ë±ìŠ¤: {target_indices}")

        # y ë°ì´í„°ë¥¼ 7ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ
        y_train = y_train[:, target_indices]
        y_test = y_test[:, target_indices]

        print(f"âœ… y ë°ì´í„° ì°¨ì› ìˆ˜ì •: {y_train.shape}, {y_test.shape}")

    return X_train, X_test, y_train, y_test, class_weights, target_stacks

# ê°œì„ ëœ ëª¨ë¸ ì •ì˜
def create_enhanced_model(input_dim, output_dim):
    """ê¸°ì¡´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê°œì„ ëœ ëª¨ë¸"""
    model = models.Sequential([
        layers.Input(shape=(input_dim,)),

        # ì²« ë²ˆì§¸ ë¸”ë¡
        layers.Dense(128, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.4),

        # ë‘ ë²ˆì§¸ ë¸”ë¡
        layers.Dense(64, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.3),

        # ì„¸ ë²ˆì§¸ ë¸”ë¡
        layers.Dense(32, activation='relu'),
        layers.Dropout(0.2),

        # ì¶œë ¥ì¸µ
        layers.Dense(output_dim, activation='sigmoid')
    ])

    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )

    return model

# ë©€í‹°ë¼ë²¨ í‰ê°€ í•¨ìˆ˜
def evaluate_multilabel_model(model, X_test, y_test, target_stacks, threshold=0.2):
    """ë©€í‹°ë¼ë²¨ ëª¨ë¸ í‰ê°€"""
    print(f"\nğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
    print(f"   íƒ€ê¹ƒ ìŠ¤íƒ: {target_stacks}")
    print(f"   y_test shape: {y_test.shape}")

    # ê° ìŠ¤íƒë³„ ì‹¤ì œ ë¶„í¬ í™•ì¸
    print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ìŠ¤íƒë³„ ë¶„í¬:")
    for i, stack in enumerate(target_stacks):
        count = np.sum(y_test[:, i])
        percentage = (count / len(y_test)) * 100
        print(f"   {stack}: {count}ê°œ ({percentage:.1f}%)")

    # ì˜ˆì¸¡
    y_pred_prob = model.predict(X_test, verbose=0)
    y_pred = (y_pred_prob > threshold).astype(int)
    # ëª¨ë¸ í•™ìŠµ ì½”ë“œì˜ evaluate í•¨ìˆ˜ ì „ì— ì¶”ê°€
    print("ğŸ” ë°ì´í„° êµ¬ì¡° ë””ë²„ê¹…:")
    print(f"y_test ìƒ˜í”Œ 5ê°œ:")
    for i in range(5):
        active_labels = np.where(y_test[i] == 1)[0]
        stack_names = [target_stacks[j] for j in active_labels]
        print(f"  ìƒ˜í”Œ {i}: {stack_names}")

    print(f"\ny_pred_prob ìƒ˜í”Œ 5ê°œ:")
    for i in range(5):
        probs = y_pred_prob[i]
        top_indices = np.argsort(probs)[::-1][:3]
        top_stacks = [(target_stacks[j], probs[j]) for j in top_indices]
        print(f"  ìƒ˜í”Œ {i}: {top_stacks}")
    # ì „ì²´ ì •í™•ë„ (ëª¨ë“  ë¼ë²¨ì´ ì •í™•í•´ì•¼ í•¨)
    exact_match_ratio = np.mean(np.all(y_pred == y_test, axis=1))

    # Hamming Loss (ë¼ë²¨ë³„ í‰ê·  ì˜¤ë¥˜ìœ¨)
    hamming_loss_score = hamming_loss(y_test, y_pred)

    # Jaccard Score (IoU)
    jaccard_score_macro = jaccard_score(y_test, y_pred, average='macro', zero_division=0)
    jaccard_score_micro = jaccard_score(y_test, y_pred, average='micro', zero_division=0)

    print(f"ğŸ¯ ë©€í‹°ë¼ë²¨ ì„±ëŠ¥ ì§€í‘œ:")
    print(f"   ì •í™•í•œ ë§¤ì¹­ ë¹„ìœ¨: {exact_match_ratio:.4f} ({exact_match_ratio:.2%})")
    print(f"   Hamming Loss: {hamming_loss_score:.4f}")
    print(f"   Jaccard Score (Macro): {jaccard_score_macro:.4f}")
    print(f"   Jaccard Score (Micro): {jaccard_score_micro:.4f}")

    # ë¼ë²¨ë³„ ì„±ëŠ¥
    print(f"\nğŸ“‹ ìŠ¤íƒë³„ ì„±ëŠ¥:")
    for i, stack in enumerate(target_stacks):
        true_positive = np.sum((y_test[:, i] == 1) & (y_pred[:, i] == 1))
        false_positive = np.sum((y_test[:, i] == 0) & (y_pred[:, i] == 1))
        false_negative = np.sum((y_test[:, i] == 1) & (y_pred[:, i] == 0))

        precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0
        recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        print(f"   {stack}: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f}")

    return exact_match_ratio, hamming_loss_score, jaccard_score_macro

# Top-k ì •í™•ë„ ê³„ì‚°
def calculate_topk_accuracy(model, X_test, y_test, target_stacks, k_values=[1, 2, 3]):
    """Top-k ì •í™•ë„ ê³„ì‚° (ê¸°ì¡´ ë°©ì‹ê³¼ í˜¸í™˜)"""
    print(f"\nğŸ¯ Top-k ì •í™•ë„ ê³„ì‚° ì¤‘...")

    y_pred_prob = model.predict(X_test, verbose=0)

    results = {}
    for k in k_values:
        # ê° ìƒ˜í”Œì— ëŒ€í•´ ìƒìœ„ kê°œ ì˜ˆì¸¡
        top_k_preds = np.argsort(y_pred_prob, axis=1)[:, -k:]

        # ì‹¤ì œ ë¼ë²¨ê³¼ ë¹„êµ
        matches = []
        for i in range(len(y_test)):
            true_labels = set(np.where(y_test[i] == 1)[0])
            pred_labels = set(top_k_preds[i])
            # êµì§‘í•©ì´ ìˆìœ¼ë©´ ì„±ê³µ
            matches.append(len(true_labels & pred_labels) > 0)

        accuracy = np.mean(matches)
        results[k] = accuracy
        print(f"   Top-{k} ì •í™•ë„: {accuracy:.4f} ({accuracy:.2%})")

    return results

# í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜
def train_and_evaluate():
    """ì „ì²´ í•™ìŠµ ë° í‰ê°€ í”„ë¡œì„¸ìŠ¤"""

    # 1. ë°ì´í„° ë¡œë“œ
    X_train, X_test, y_train, y_test, class_weights, target_stacks = load_processed_data()

    # 2. ëª¨ë¸ ìƒì„±
    input_dim = X_train.shape[1]
    output_dim = 7

    print(f"\nğŸ¤– ëª¨ë¸ ìƒì„± ì¤‘...")
    print(f"   ì…ë ¥ ì°¨ì›: {input_dim}")
    print(f"   ì¶œë ¥ ì°¨ì›: {output_dim} (7ê°œ ê¸°ë³¸ ìŠ¤íƒ)")

    model = create_enhanced_model(input_dim, output_dim)
    model.summary()

    # 3. ì½œë°± ì„¤ì •
    callbacks_list = [
        callbacks.EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True,
            verbose=1
        ),
        callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=8,
            min_lr=1e-7,
            verbose=1
        ),
        callbacks.ModelCheckpoint(
            'best_multilabel_model.keras',
            monitor='val_loss',
            save_best_only=True,
            verbose=1
        )
    ]

    # 4. ëª¨ë¸ í•™ìŠµ
    print(f"\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

    history = model.fit(
        X_train, y_train,
        validation_data=(X_test, y_test),
        batch_size=32,
        epochs=100,
        class_weight=class_weights,  # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©
        callbacks=callbacks_list,
        verbose=1
    )
    # 5. ëª¨ë¸ í‰ê°€
    print(f"\nğŸ“Š ìµœì¢… í‰ê°€:")

    # ë©€í‹°ë¼ë²¨ í‰ê°€
    exact_match, hamming_loss, jaccard_macro = evaluate_multilabel_model(
        model, X_test, y_test, target_stacks
    )

    # Top-k ì •í™•ë„ (ê¸°ì¡´ ë°©ì‹ê³¼ ë¹„êµìš©)
    topk_results = calculate_topk_accuracy(model, X_test, y_test, target_stacks)

    # 6. ê²°ê³¼ ì‹œê°í™”
    plot_training_history(history)
    plot_prediction_analysis(model, X_test, y_test, target_stacks)

    # 7. ìµœì¢… ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ‰ ìµœì¢… ì„±ëŠ¥ ìš”ì•½:")
    print(f"   ì •í™•í•œ ë§¤ì¹­: {exact_match:.2%}")
    print(f"   Top-1 ì •í™•ë„: {topk_results[1]:.2%}")
    print(f"   Top-2 ì •í™•ë„: {topk_results[2]:.2%}")
    print(f"   Jaccard Score: {jaccard_macro:.4f}")

    return model, history, exact_match, topk_results

# í•™ìŠµ ê³¡ì„  ì‹œê°í™”
def plot_training_history(history):
    """í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Loss
    axes[0,0].plot(history.history['loss'], label='Training Loss')
    axes[0,0].plot(history.history['val_loss'], label='Validation Loss')
    axes[0,0].set_title('Model Loss')
    axes[0,0].set_xlabel('Epoch')
    axes[0,0].set_ylabel('Loss')
    axes[0,0].legend()
    axes[0,0].grid(True, alpha=0.3)

    # Accuracy
    axes[0,1].plot(history.history['accuracy'], label='Training Accuracy')
    axes[0,1].plot(history.history['val_accuracy'], label='Validation Accuracy')
    axes[0,1].set_title('Model Accuracy')
    axes[0,1].set_xlabel('Epoch')
    axes[0,1].set_ylabel('Accuracy')
    axes[0,1].legend()
    axes[0,1].grid(True, alpha=0.3)

    # Precision
    if 'precision' in history.history:
        axes[1,0].plot(history.history['precision'], label='Training Precision')
        axes[1,0].plot(history.history['val_precision'], label='Validation Precision')
        axes[1,0].set_title('Model Precision')
        axes[1,0].set_xlabel('Epoch')
        axes[1,0].set_ylabel('Precision')
        axes[1,0].legend()
        axes[1,0].grid(True, alpha=0.3)

    # Recall
    if 'recall' in history.history:
        axes[1,1].plot(history.history['recall'], label='Training Recall')
        axes[1,1].plot(history.history['val_recall'], label='Validation Recall')
        axes[1,1].set_title('Model Recall')
        axes[1,1].set_xlabel('Epoch')
        axes[1,1].set_ylabel('Recall')
        axes[1,1].legend()
        axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

# ì˜ˆì¸¡ ë¶„ì„ ì‹œê°í™”
def plot_prediction_analysis(model, X_test, y_test, target_stacks):
    """ì˜ˆì¸¡ ë¶„ì„ ì‹œê°í™”"""
    y_pred_prob = model.predict(X_test, verbose=0)
    y_pred = (y_pred_prob > 0.5).astype(int)

    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # ì‹¤ì œ vs ì˜ˆì¸¡ ë¶„í¬
    true_counts = np.sum(y_test, axis=0)
    pred_counts = np.sum(y_pred, axis=0)

    x = range(len(target_stacks))
    width = 0.35

    axes[0].bar([i - width/2 for i in x], true_counts, width, label='ì‹¤ì œ', alpha=0.8)
    axes[0].bar([i + width/2 for i in x], pred_counts, width, label='ì˜ˆì¸¡', alpha=0.8)
    axes[0].set_xlabel('ìŠ¤íƒ')
    axes[0].set_ylabel('ìƒ˜í”Œ ìˆ˜')
    axes[0].set_title('ì‹¤ì œ vs ì˜ˆì¸¡ ë¶„í¬')
    axes[0].set_xticks(x)
    axes[0].set_xticklabels(target_stacks, rotation=45)
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # ì˜ˆì¸¡ í™•ë¥  ë¶„í¬
    axes[1].boxplot([y_pred_prob[:, i] for i in range(len(target_stacks))],
                    labels=target_stacks)
    axes[1].set_xlabel('ìŠ¤íƒ')
    axes[1].set_ylabel('ì˜ˆì¸¡ í™•ë¥ ')
    axes[1].set_title('ìŠ¤íƒë³„ ì˜ˆì¸¡ í™•ë¥  ë¶„í¬')
    axes[1].tick_params(axis='x', rotation=45)
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸš€ ë©€í‹°ë¼ë²¨ ìŠ¤íƒ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì‹œì‘!")
    print("=" * 60)

    # í•™ìŠµ ë° í‰ê°€ ì‹¤í–‰
    model, history, exact_match, topk_results = train_and_evaluate()

    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼: best_multilabel_model.keras")