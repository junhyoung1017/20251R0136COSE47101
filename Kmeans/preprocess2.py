import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
import pickle
import re
from typing import Tuple, List
import os

# íŒŒì¼ ê²½ë¡œ
file_path = 'C:/Users/jun01/OneDrive/ë°”íƒ• í™”ë©´/ê³ ë ¤ëŒ€/ë°ê³¼/TermProject/20251R0136COSE47101/Kmeans/github_profiles_total_v4.3.csv'

def split_repos(text: str) -> Tuple[str, str]:
    """
    Repository í…ìŠ¤íŠ¸ë¥¼ ì´ë¦„ê³¼ ì„¤ëª…ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜
    """
    if pd.isna(text) or text == '':
        return '', ''
    
    repos = str(text).split('/')  # ê° repo êµ¬ë¶„
    repo_names = []
    descriptions = []
    
    for repo in repos:
        parts = repo.split('::')
        name = parts[0].strip()
        desc = parts[1].strip() if len(parts) > 1 else ''
        
        # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
        if name and name != 'nan':
            repo_names.append(name)
        if desc and desc != 'nan':
            descriptions.append(desc)
    
    return ', '.join(repo_names), ', '.join(descriptions)

def clean_text(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ (íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì†Œë¬¸ì ë³€í™˜ ë“±)
    """
    if pd.isna(text) or text == '':
        return ''
    
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì˜ë¬¸, ìˆ«ì, ê³µë°±ë§Œ ë‚¨ê¹€)
    text = re.sub(r'[^a-zA-Z0-9\s]', ' ', str(text))
    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text)
    # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()
    
    return text



def main():
    print("ğŸ“ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # ë°ì´í„° ë¡œë”© (ì¸ì½”ë”© ì—ëŸ¬ ì²˜ë¦¬)
    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
            df = pd.read_csv(f)
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return
    
    print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ. ì´ {len(df)}ê°œ í–‰")
    print(f"ğŸ“Š ì»¬ëŸ¼: {list(df.columns)}")
    
    # 1. ì–¸ì–´ ë°ì´í„° í†µí•©
    print("\nğŸ”„ ì–¸ì–´ ë°ì´í„° í†µí•© ì¤‘...")
    
    # JavaScript + TypeScript = JS
    if 'JavaScript' in df.columns and 'TypeScript' in df.columns:
        df["JS"] = df[['JavaScript', 'TypeScript']].sum(axis=1)
        df.drop(columns=['JavaScript', 'TypeScript'], inplace=True)
        print("âœ… JavaScript + TypeScript â†’ JS í†µí•© ì™„ë£Œ")
    
    # C + C++ = C/C++
    if 'C' in df.columns and 'C++' in df.columns:
        df["C/C++"] = df[['C', 'C++']].sum(axis=1)
        df.drop(columns=['C', 'C++'], inplace=True)
        print("âœ… C + C++ â†’ C/C++ í†µí•© ì™„ë£Œ")
    
    # 2. Repository ì´ë¦„ê³¼ ì„¤ëª… ë¶„ë¦¬
    print("\nğŸ“ Repository í…ìŠ¤íŠ¸ ë¶„ë¦¬ ì¤‘...")
    
    if 'text' in df.columns:
        df[['repo_names', 'description']] = df['text'].apply(lambda x: pd.Series(split_repos(x)))
        df.drop(columns=['text'], inplace=True)
        print("âœ… Repository ì´ë¦„ê³¼ ì„¤ëª… ë¶„ë¦¬ ì™„ë£Œ")
        
        # ë¶„ë¦¬ ê²°ê³¼ í™•ì¸
        print(f"ğŸ“‹ Repository ì´ë¦„ ìƒ˜í”Œ:\n{df['repo_names'].head()}")
        print(f"ğŸ“‹ Description ìƒ˜í”Œ:\n{df['description'].head()}")
    
    # 3. ì–¸ì–´ ì»¬ëŸ¼ í™•ì¸
    print("\nğŸ“Š ì–¸ì–´ ë°ì´í„° í™•ì¸ ì¤‘...")
    
    # ì–¸ì–´ ì»¬ëŸ¼ ì‹ë³„ (ìˆ«ìí˜• ë°ì´í„°ì¸ ì»¬ëŸ¼ë“¤)
    exclude_columns = {'user_ID', 'username', 'repo_count', 'repo_names', 'description', 'stack', 'note'}
    language_columns = [col for col in df.columns if col not in exclude_columns and df[col].dtype in ['int64', 'float64']]
    
    print(f"ğŸ¯ ì–¸ì–´ ì»¬ëŸ¼: {language_columns}")
    print("âœ… ì–¸ì–´ ë°ì´í„° í™•ì¸ ì™„ë£Œ")
    
    # 4. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    print("\nğŸ§¹ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¤‘...")
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì •ì œ
    df['description'] = df['description'].fillna('').apply(clean_text)
    df['repo_names'] = df['repo_names'].fillna('').apply(clean_text)
    
    # ë¹ˆ ë¬¸ìì—´ì„ "no description" ë˜ëŠ” "no repository"ë¡œ ëŒ€ì²´ (BERT ì„ë² ë”©ì„ ìœ„í•´)
    df['description'] = df['description'].replace('', 'no description available')
    df['repo_names'] = df['repo_names'].replace('', 'no repository name')
    
    print("âœ… í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì™„ë£Œ")
    
    # 5. BERT ì„ë² ë”© ìƒì„±
    print("\nğŸ¤– BERT ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    try:
        # ì‚¬ì „ í•™ìŠµëœ BERT ê¸°ë°˜ ëª¨ë¸ ë¡œë“œ (ë‹¤êµ­ì–´ ì§€ì› ëª¨ë¸ë¡œ ë³€ê²½ ê°€ëŠ¥)
        model = SentenceTransformer('all-MiniLM-L6-v2')  # ë¹ ë¥´ê³  íš¨ê³¼ì ì¸ ëª¨ë¸
        print("âœ… BERT ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # Description ì„ë² ë”© ìƒì„±
        print("\nğŸ“ Description ì„ë² ë”© ìƒì„± ì¤‘...")
        description_embeddings = model.encode(
            df['description'].tolist(), 
            show_progress_bar=True,
            batch_size=32,  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ ë°°ì¹˜ í¬ê¸° ì„¤ì •
            convert_to_numpy=True
        )
        
        # Repository names ì„ë² ë”© ìƒì„±
        print("\nğŸ“ Repository names ì„ë² ë”© ìƒì„± ì¤‘...")
        name_embeddings = model.encode(
            df['repo_names'].tolist(), 
            show_progress_bar=True,
            batch_size=32,
            convert_to_numpy=True
        )
        
        print("âœ… BERT ì„ë² ë”© ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ BERT ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # 6. ì„ë² ë”©ì„ DataFrameìœ¼ë¡œ ë³€í™˜ ë° ê²°í•©
    print("\nğŸ”— ë°ì´í„° ê²°í•© ì¤‘...")
    
    # Description ì„ë² ë”© DataFrame ìƒì„±
    embedding_df = pd.DataFrame(
        description_embeddings, 
        columns=[f'bert_desc_{i}' for i in range(description_embeddings.shape[1])]
    )
    
    # Repository names ì„ë² ë”© DataFrame ìƒì„±
    name_df = pd.DataFrame(
        name_embeddings, 
        columns=[f'bert_name_{i}' for i in range(name_embeddings.shape[1])]
    )
    
    # ê¸°ì¡´ DataFrameê³¼ ê²°í•©
    df = pd.concat([df.reset_index(drop=True), name_df, embedding_df], axis=1)
    
    print("âœ… ë°ì´í„° ê²°í•© ì™„ë£Œ")
    print(f"ğŸ“Š ìµœì¢… DataFrame í¬ê¸°: {df.shape}")
    
    # 7. ê²°ê³¼ ì €ì¥
    print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    output_dir = 'C:/Users/jun01/OneDrive/ë°”íƒ• í™”ë©´/ê³ ë ¤ëŒ€/ë°ê³¼/TermProject/'
    os.makedirs(output_dir, exist_ok=True)
    
    pickle_path = os.path.join(output_dir, 'github_profiles_with_bert_processed.pkl')
    csv_path = os.path.join(output_dir, 'github_profiles_with_bert_processed.csv')
    
    try:
        # í”¼í´ í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì„ë² ë”© ë°ì´í„° ë³´ì¡´)
        df.to_pickle(pickle_path)
        print(f"âœ… í”¼í´ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {pickle_path}")
        
        '''# CSV í˜•ì‹ìœ¼ë¡œë„ ì €ì¥ (ì¼ë¶€ ì»¬ëŸ¼ë§Œ)
        # BERT ì„ë² ë”©ì€ ë„ˆë¬´ í¬ë¯€ë¡œ ì›ë³¸ ë°ì´í„°ì™€ ì–¸ì–´ í†µê³„ë§Œ ì €ì¥
        basic_columns = [col for col in df.columns if not col.startswith('bert_')]
        df[basic_columns].to_csv(csv_path, index=False, encoding='utf-8')
        print(f"âœ… CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_path}")'''
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return
    
    # 8. ê²°ê³¼ ìš”ì•½
    print("\nğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:")
    print(f"â€¢ ì´ ì‚¬ìš©ì ìˆ˜: {len(df)}")
    print(f"â€¢ ì–¸ì–´ ì»¬ëŸ¼ ìˆ˜: {len(language_columns)}")
    print(f"â€¢ Description ì„ë² ë”© ì°¨ì›: {description_embeddings.shape[1]}")
    print(f"â€¢ Repository names ì„ë² ë”© ì°¨ì›: {name_embeddings.shape[1]}")
    print(f"â€¢ ìµœì¢… í”¼ì²˜ ìˆ˜: {df.shape[1]}")
    
    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
    print(f"\nğŸ“‹ ìµœì¢… ë°ì´í„° ìƒ˜í”Œ:")
    display_columns = ['username', 'repo_count'] + language_columns[:3] + ['repo_names', 'description']
    available_columns = [col for col in display_columns if col in df.columns]
    print(df[available_columns].head())
    
    print("\nğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")

if __name__ == "__main__":
    main()