import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_selection import SelectKBest, f_classif
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì • (matplotlib)
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

def load_and_explore_data(pkl_path):
    """
    í”¼í´ íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë°ì´í„°ë¥¼ íƒìƒ‰í•˜ëŠ” í•¨ìˆ˜
    """
    print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
    df = pd.read_pickle(pkl_path)
    
    print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
    print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {df.shape}")
    print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    # ì»¬ëŸ¼ ë¶„ë¥˜
    basic_cols = [col for col in df.columns if not col.startswith('bert_')]
    bert_name_cols = [col for col in df.columns if col.startswith('bert_name_')]
    bert_desc_cols = [col for col in df.columns if col.startswith('bert_desc_')]
    
    print(f"\nğŸ“‹ ì»¬ëŸ¼ êµ¬ì„±:")
    print(f"â€¢ ê¸°ë³¸ ì»¬ëŸ¼: {len(basic_cols)}ê°œ")
    print(f"â€¢ BERT name ì„ë² ë”©: {len(bert_name_cols)}ê°œ")
    print(f"â€¢ BERT description ì„ë² ë”©: {len(bert_desc_cols)}ê°œ")
    
    # íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸
    if 'stack' in df.columns:
        print(f"\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (stack) ë¶„í¬:")
        stack_counts = df['stack'].value_counts()
        print(stack_counts)
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        null_count = df['stack'].isnull().sum()
        print(f"\nâ— ê²°ì¸¡ì¹˜: {null_count}ê°œ ({null_count/len(df)*100:.2f}%)")
        
        return df, basic_cols, bert_name_cols, bert_desc_cols, stack_counts
    else:
        print("âŒ 'stack' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return df, basic_cols, bert_name_cols, bert_desc_cols, None

def prepare_features(df, basic_cols, bert_name_cols, bert_desc_cols):
    """
    ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ í”¼ì²˜ ì¤€ë¹„
    """
    print("\nğŸ”§ í”¼ì²˜ ì¤€ë¹„ ì¤‘...")
    
    # 1. ì–¸ì–´ í†µê³„ í”¼ì²˜ ì¶”ì¶œ
    exclude_cols = {'user_ID', 'username', 'repo_names', 'description', 'stack', 'note'}
    language_cols = [col for col in basic_cols if col not in exclude_cols and df[col].dtype in ['int64', 'float64']]
    
    print(f"ğŸ¯ ì–¸ì–´ í†µê³„ í”¼ì²˜: {language_cols}")
    
    # 2. ê¸°ë³¸ ì •ë³´ í”¼ì²˜
    basic_info_cols = ['repo_count'] if 'repo_count' in df.columns else []
    
    # 3. ì „ì²´ í”¼ì²˜ ê²°í•©
    feature_columns = language_cols + basic_info_cols + bert_name_cols + bert_desc_cols
    
    print(f"ğŸ“Š ì´ í”¼ì²˜ ìˆ˜: {len(feature_columns)}")
    print(f"â€¢ ì–¸ì–´ í†µê³„: {len(language_cols)}ê°œ")
    print(f"â€¢ ê¸°ë³¸ ì •ë³´: {len(basic_info_cols)}ê°œ") 
    print(f"â€¢ BERT name: {len(bert_name_cols)}ê°œ")
    print(f"â€¢ BERT desc: {len(bert_desc_cols)}ê°œ")
    
    # í”¼ì²˜ ë°ì´í„° ì¶”ì¶œ
    X = df[feature_columns].copy()
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    print(f"\nğŸ” ê²°ì¸¡ì¹˜ í™•ì¸:")
    null_counts = X.isnull().sum()
    if null_counts.sum() > 0:
        print(f"ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼: {null_counts[null_counts > 0]}")
        X = X.fillna(0)  # ê²°ì¸¡ì¹˜ë¥¼ 0ìœ¼ë¡œ ì±„ì›€
        print("âœ… ê²°ì¸¡ì¹˜ë¥¼ 0ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("âœ… ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    return X, feature_columns, language_cols

def prepare_target(df):
    """
    íƒ€ê²Ÿ ë³€ìˆ˜ ì¤€ë¹„
    """
    print("\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ì¤€ë¹„ ì¤‘...")
    
    # ê²°ì¸¡ì¹˜ ì œê±°
    valid_mask = df['stack'].notna()
    print(f"ìœ íš¨í•œ íƒ€ê²Ÿ ë°ì´í„°: {valid_mask.sum()}ê°œ")
    
    if valid_mask.sum() == 0:
        raise ValueError("ëª¨ë“  íƒ€ê²Ÿ ê°’ì´ ê²°ì¸¡ì¹˜ì…ë‹ˆë‹¤!")
    
    # ë ˆì´ë¸” ì¸ì½”ë”©
    le = LabelEncoder()
    y_encoded = le.fit_transform(df.loc[valid_mask, 'stack'])
    
    print(f"âœ… íƒ€ê²Ÿ í´ë˜ìŠ¤ ìˆ˜: {len(le.classes_)}")
    print(f"í´ë˜ìŠ¤ ëª©ë¡: {list(le.classes_)}")
    
    return y_encoded, valid_mask, le

def feature_selection(X_train, y_train, k=1000):
    """
    ì¤‘ìš”í•œ í”¼ì²˜ ì„ íƒ (ë„ˆë¬´ ë§ì€ í”¼ì²˜ë¡œ ì¸í•œ ê³¼ì í•© ë°©ì§€)
    """
    print(f"\nğŸ” í”¼ì²˜ ì„ íƒ ì¤‘ (ìƒìœ„ {k}ê°œ)...")
    
    if X_train.shape[1] <= k:
        print(f"ì „ì²´ í”¼ì²˜ ìˆ˜({X_train.shape[1]})ê°€ ì„ íƒ ê°œìˆ˜({k})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤.")
        return X_train, X_train.columns, None
    
    selector = SelectKBest(score_func=f_classif, k=k)
    X_selected = selector.fit_transform(X_train, y_train)
    
    # ì„ íƒëœ í”¼ì²˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    selected_features = X_train.columns[selector.get_support()]
    
    print(f"âœ… {len(selected_features)}ê°œ í”¼ì²˜ ì„ íƒ ì™„ë£Œ")
    
    return X_selected, selected_features, selector

def train_models(X_train, y_train, X_test, y_test):
    """
    ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    """
    print("\nğŸ¤– ëª¨ë¸ í•™ìŠµ ì¤‘...")
    
    models = {
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
        'SVM': SVC(random_state=42, probability=True)
    }
    
    results = {}
    
    for name, model in models.items():
        print(f"\nğŸ”„ {name} í•™ìŠµ ì¤‘...")
        
        # ëª¨ë¸ í•™ìŠµ
        model.fit(X_train, y_train)
        
        # ì˜ˆì¸¡
        y_pred = model.predict(X_test)
        
        # í‰ê°€
        accuracy = accuracy_score(y_test, y_pred)
        
        # êµì°¨ ê²€ì¦
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
        
        results[name] = {
            'model': model,
            'accuracy': accuracy,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'predictions': y_pred
        }
        
        print(f"âœ… {name} ì™„ë£Œ!")
        print(f"   í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f}")
        print(f"   êµì°¨ ê²€ì¦ ì •í™•ë„: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
    
    return results

def evaluate_best_model(results, X_test, y_test, label_encoder):
    """
    ìµœê³  ì„±ëŠ¥ ëª¨ë¸ í‰ê°€ ë° ê²°ê³¼ ì¶œë ¥
    """
    print("\nğŸ† ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:")
    print("-" * 60)
    
    # ì„±ëŠ¥ ë¹„êµ
    for name, result in results.items():
        print(f"{name:20} | í…ŒìŠ¤íŠ¸: {result['accuracy']:.4f} | CV: {result['cv_mean']:.4f}Â±{result['cv_std']:.4f}")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
    best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])
    best_result = results[best_model_name]
    
    print(f"\nğŸ¥‡ ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
    print(f"   í…ŒìŠ¤íŠ¸ ì •í™•ë„: {best_result['accuracy']:.4f}")
    
    # ìƒì„¸ ë¶„ë¥˜ ë³´ê³ ì„œ
    print(f"\nğŸ“Š {best_model_name} ìƒì„¸ í‰ê°€:")
    y_pred = best_result['predictions']
    
    # í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
    y_test_labels = label_encoder.inverse_transform(y_test)
    y_pred_labels = label_encoder.inverse_transform(y_pred)
    
    print("\në¶„ë¥˜ ë³´ê³ ì„œ:")
    print(classification_report(y_test_labels, y_pred_labels))
    
    return best_result['model'], best_model_name

def visualize_results(results, y_test, label_encoder):
    """
    ê²°ê³¼ ì‹œê°í™”
    """
    print("\nğŸ“ˆ ê²°ê³¼ ì‹œê°í™” ì¤‘...")
    
    # 1. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # ì„±ëŠ¥ ë¹„êµ ë°” ì°¨íŠ¸
    model_names = list(results.keys())
    accuracies = [results[name]['accuracy'] for name in model_names]
    cv_means = [results[name]['cv_mean'] for name in model_names]
    
    axes[0, 0].bar(model_names, accuracies, alpha=0.7, label='Test Accuracy')
    axes[0, 0].bar(model_names, cv_means, alpha=0.7, label='CV Mean')
    axes[0, 0].set_title('Model Performance Comparison')
    axes[0, 0].set_ylabel('Accuracy')
    axes[0, 0].legend()
    axes[0, 0].tick_params(axis='x', rotation=45)
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ í˜¼ë™ í–‰ë ¬
    best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])
    y_pred = results[best_model_name]['predictions']
    
    # í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
    y_test_labels = label_encoder.inverse_transform(y_test)
    y_pred_labels = label_encoder.inverse_transform(y_pred)
    
    cm = confusion_matrix(y_test_labels, y_pred_labels)
    
    axes[0, 1].remove()
    axes[1, 0].remove() 
    axes[1, 1].remove()
    
    # í˜¼ë™ í–‰ë ¬ì„ í° ì„œë¸Œí”Œë¡¯ì— ê·¸ë¦¬ê¸°
    ax_cm = plt.subplot(2, 2, (2, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=label_encoder.classes_, 
                yticklabels=label_encoder.classes_,
                ax=ax_cm)
    ax_cm.set_title(f'{best_model_name} - Confusion Matrix')
    ax_cm.set_ylabel('True Label')
    ax_cm.set_xlabel('Predicted Label')
    
    plt.tight_layout()
    plt.show()

def main():
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    pkl_path = 'C:/Users/jun01/OneDrive/ë°”íƒ• í™”ë©´/ê³ ë ¤ëŒ€/ë°ê³¼/TermProject/github_profiles_with_bert_processed.pkl'
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰
        df, basic_cols, bert_name_cols, bert_desc_cols, stack_counts = load_and_explore_data(pkl_path)
        
        if stack_counts is None:
            return
        
        # 2. í”¼ì²˜ ì¤€ë¹„
        X, feature_columns, language_cols = prepare_features(df, basic_cols, bert_name_cols, bert_desc_cols)
        
        # 3. íƒ€ê²Ÿ ì¤€ë¹„
        y, valid_mask, label_encoder = prepare_target(df)
        
        # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì„ íƒ
        X = X.loc[valid_mask].reset_index(drop=True)
        
        print(f"\nğŸ“Š ìµœì¢… ë°ì´í„° í¬ê¸°: {X.shape}")
        print(f"íƒ€ê²Ÿ ë°ì´í„° í¬ê¸°: {len(y)}")
        
        # 4. ë°ì´í„° ë¶„í• 
        print("\nğŸ”€ ë°ì´í„° ë¶„í•  ì¤‘...")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"í•™ìŠµ ë°ì´í„°: {X_train.shape}")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")
        
        # 5. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ (BERT ë²¡í„°ëŠ” ì´ë¯¸ ì •ê·œí™”ë˜ì–´ ìˆì§€ë§Œ, ì–¸ì–´ í†µê³„ëŠ” ìŠ¤ì¼€ì¼ë§ í•„ìš”)
        print("\nâš–ï¸ í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ì¤‘...")
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # DataFrame í˜•íƒœë¡œ ë³€í™˜
        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)
        
        # 6. í”¼ì²˜ ì„ íƒ (ì„ íƒì‚¬í•­ - ë„ˆë¬´ ë§ì€ í”¼ì²˜ê°€ ìˆì„ ë•Œ)
        if X_train_scaled.shape[1] > 1000:
            X_train_selected, selected_features, selector = feature_selection(X_train_scaled, y_train, k=1000)
            X_test_selected = selector.transform(X_test_scaled)
            
            # DataFrameìœ¼ë¡œ ë³€í™˜
            X_train_final = pd.DataFrame(X_train_selected, columns=selected_features)
            X_test_final = pd.DataFrame(X_test_selected, columns=selected_features)
        else:
            X_train_final = X_train_scaled
            X_test_final = X_test_scaled
        
        # 7. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
        results = train_models(X_train_final, y_train, X_test_final, y_test)
        
        # 8. ìµœê³  ëª¨ë¸ í‰ê°€
        best_model, best_model_name = evaluate_best_model(results, X_test_final, y_test, label_encoder)
        
        # 9. ê²°ê³¼ ì‹œê°í™”
        visualize_results(results, y_test, label_encoder)
        
        # 10. ëª¨ë¸ ì €ì¥
        import pickle
        model_save_path = pkl_path.replace('.pkl', '_best_model.pkl')
        
        model_data = {
            'model': best_model,
            'scaler': scaler,
            'label_encoder': label_encoder,
            'feature_columns': feature_columns,
            'selected_features': X_train_final.columns.tolist() if 'selector' in locals() else None,
            'selector': selector if 'selector' in locals() else None,
            'model_name': best_model_name
        }
        
        with open(model_save_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"\nğŸ’¾ ìµœê³  ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")
        print(f"ëª¨ë¸: {best_model_name}")
        print(f"ì„±ëŠ¥: {results[best_model_name]['accuracy']:.4f}")
        
        print("\nğŸ‰ ìŠ¤íƒ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()